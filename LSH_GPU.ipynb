{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cupy as cp\n",
    "from numba import cuda,jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_with_test.csv')\n",
    "def lower_all_characters(text):\n",
    "    return text.lower()\n",
    "\n",
    "df['genres'] = df['genres'].astype(str).apply(lower_all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shingles(text, min_length=1, max_length=None):\n",
    "    tags = [tag.strip() for tag in text.split(',')]  # Split tags by comma and remove any extra whitespace\n",
    "\n",
    "    all_shingles = set()\n",
    "    for tag in tags:\n",
    "        words = tag.split()  # Split tag into words\n",
    "        if max_length is None:\n",
    "            max_length = max(len(word) for word in words)  # Set max_length to the length of the longest word if not provided\n",
    "\n",
    "        for word in words:\n",
    "            # Generate shingles starting from the beginning of the word\n",
    "            for i in range(min_length, len(word) + 1):\n",
    "                all_shingles.add(word[:i])\n",
    "                    \n",
    "    return all_shingles\n",
    "\n",
    "df['shingles'] = df['genres'].apply(create_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minht\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create hash functions with coefficients a and b\n",
    "def create_hash_functions(num_hash_functions, max_val):\n",
    "    hash_functions = []\n",
    "    random.seed(40)\n",
    "    for _ in range(num_hash_functions):\n",
    "        a = random.randint(1, max_val)\n",
    "        b = random.randint(0, max_val)\n",
    "        hash_functions.append((a, b))\n",
    "    return hash_functions\n",
    "\n",
    "# Convert hash functions to arrays for CUDA\n",
    "def hash_functions_to_arrays(hash_functions):\n",
    "    a_array = np.array([func[0] for func in hash_functions], dtype=np.int32)\n",
    "    b_array = np.array([func[1] for func in hash_functions], dtype=np.int32)\n",
    "    return a_array, b_array\n",
    "\n",
    "# CUDA kernel to compute hash functions and update signatures\n",
    "@cuda.jit\n",
    "def cuda_hash_function(shingles, num_hashes, signatures, a_array, b_array, max_val):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < shingles.shape[0]:\n",
    "        for i in range(num_hashes):\n",
    "            hash_value = 2**32 - 1  # A large constant instead of inf\n",
    "            for j in range(shingles.shape[1]):\n",
    "                if shingles[idx, j] == 0:\n",
    "                    break\n",
    "                current_hash = (a_array[i] * shingles[idx, j] + b_array[i]) % max_val\n",
    "                hash_value = min(hash_value, current_hash)\n",
    "            signatures[idx, i] = hash_value\n",
    "\n",
    "# Compute MinHash signatures on GPU\n",
    "def minhash_signatures_cuda(movies, num_hash_functions=30):\n",
    "    all_shingles = set()\n",
    "    for shingles in movies.values():\n",
    "        all_shingles.update(shingles)\n",
    "    max_val = len(all_shingles)  # Set max_val to the number of unique shingles\n",
    "\n",
    "    hash_functions = create_hash_functions(num_hash_functions, max_val)\n",
    "    a_array, b_array = hash_functions_to_arrays(hash_functions)\n",
    "\n",
    "    # Convert shingles to numerical values for CUDA\n",
    "    max_shingle_len = max(len(shingles) for shingles in movies.values())\n",
    "    shingles_gpu = np.zeros((len(movies), max_shingle_len), dtype=np.int32)\n",
    "    signatures_gpu = np.full((len(movies), num_hash_functions), 2**32 - 1, dtype=np.int32)  # Use large constant\n",
    "\n",
    "    for i, shingles in enumerate(movies.values()):\n",
    "        shingle_hashes = np.array([sum(ord(c) for c in shingle) for shingle in shingles], dtype=np.int32)\n",
    "        shingles_gpu[i, :len(shingle_hashes)] = shingle_hashes\n",
    "\n",
    "    # Transfer data to GPU\n",
    "    shingles_gpu_device = cuda.to_device(shingles_gpu)\n",
    "    signatures_gpu_device = cuda.to_device(signatures_gpu)\n",
    "    a_array_device = cuda.to_device(a_array)\n",
    "    b_array_device = cuda.to_device(b_array)\n",
    "\n",
    "    # Launch CUDA kernel\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (len(movies) + threads_per_block - 1) // threads_per_block\n",
    "    cuda_hash_function[blocks_per_grid, threads_per_block](shingles_gpu_device, num_hash_functions, signatures_gpu_device, a_array_device, b_array_device, max_val)\n",
    "\n",
    "    # Copy signatures back to CPU\n",
    "    signatures_cpu = signatures_gpu_device.copy_to_host()\n",
    "\n",
    "    # Convert results to dictionary format\n",
    "    signatures_dict = {title: signatures_cpu[i].tolist() for i, title in enumerate(movies.keys())}\n",
    "\n",
    "    return signatures_dict\n",
    "\n",
    "\n",
    "# Sample DataFrame processing\n",
    "df['shingles'] = df['genres'].astype(str).apply(create_shingles)\n",
    "new_signatures_cuda = minhash_signatures_cuda(df.set_index('originalTitle')['shingles'].to_dict())\n",
    "df['minhash_signature'] = df['originalTitle'].map(new_signatures_cuda)\n",
    "df.to_csv('temp_gpu.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, num_bands, num_rows_per_band, max_val):\n",
    "        self.num_bands = num_bands\n",
    "        self.num_rows_per_band = num_rows_per_band\n",
    "        self.max_val = max_val\n",
    "        self.df = pd.read_csv('movie_with_test.csv')\n",
    "        self.buckets = {}\n",
    "\n",
    "    def insert_parallel(self, signatures_dict):\n",
    "        \"\"\"\n",
    "        Insert MinHash signatures into LSH buckets in parallel.\n",
    "        \"\"\"\n",
    "        # Convert movie titles to unique indices\n",
    "        titles = list(signatures_dict.keys())\n",
    "        title_to_index = {title: i for i, title in enumerate(titles)}\n",
    "        index_to_title = {i: title for title, i in title_to_index.items()}\n",
    "\n",
    "        num_movies = len(titles)\n",
    "\n",
    "        # Initialize arrays\n",
    "        keys = np.array([title_to_index[title] for title in signatures_dict.keys()], dtype=np.int32)\n",
    "        signatures = np.array(list(signatures_dict.values()), dtype=np.int32)\n",
    "\n",
    "        # Use dictionary to store bucket entries\n",
    "        buckets_dict = {}\n",
    "        \n",
    "        # Transfer data to GPU\n",
    "        keys_device = cuda.to_device(keys)\n",
    "        signatures_device = cuda.to_device(signatures)\n",
    "\n",
    "        # Define kernel\n",
    "        @cuda.jit\n",
    "        def parallel_insert(keys, signatures, num_bands, num_rows_per_band, max_buckets, bucket_ids):\n",
    "            idx = cuda.grid(1)\n",
    "            if idx < keys.size:\n",
    "                key = keys[idx]\n",
    "                signature = signatures[idx]\n",
    "                for band_index in range(num_bands):\n",
    "                    start_row = band_index * num_rows_per_band\n",
    "                    end_row = start_row + num_rows_per_band\n",
    "                    band_signature = 0\n",
    "                    for row in range(start_row, end_row):\n",
    "                        band_signature = (band_signature * 31 + signature[row]) & 0xFFFFFFFF\n",
    "                    bucket_id = band_signature % max_buckets\n",
    "                    bucket_ids[idx, band_index] = bucket_id\n",
    "\n",
    "        # Prepare data for bucket IDs\n",
    "        bucket_ids = np.zeros((num_movies, self.num_bands), dtype=np.int32)\n",
    "        bucket_ids_device = cuda.to_device(bucket_ids)\n",
    "\n",
    "        # Launch kernel\n",
    "        threads_per_block = 256\n",
    "        blocks_per_grid = (num_movies + threads_per_block - 1) // threads_per_block\n",
    "        parallel_insert[blocks_per_grid, threads_per_block](keys_device, signatures_device, self.num_bands, self.num_rows_per_band, self.max_val, bucket_ids_device)\n",
    "\n",
    "        # Copy bucket_ids back to CPU\n",
    "        bucket_ids_cpu = bucket_ids_device.copy_to_host()\n",
    "\n",
    "        # Fill bucket dictionary\n",
    "        for i in range(num_movies):\n",
    "            key = titles[i]\n",
    "            for band_index in range(self.num_bands):\n",
    "                bucket_id = bucket_ids_cpu[i, band_index]\n",
    "                if bucket_id not in buckets_dict:\n",
    "                    buckets_dict[bucket_id] = []\n",
    "                buckets_dict[bucket_id].append(key)\n",
    "\n",
    "        self.buckets = buckets_dict\n",
    "\n",
    "    def movie_similar(self, query_signature):\n",
    "        \"\"\"\n",
    "        Query similar items based on MinHash signature of the query.\n",
    "        \"\"\"\n",
    "        candidates = set()\n",
    "        # Iterate through bands\n",
    "        for band_index in range(self.num_bands):\n",
    "            start_row = band_index * self.num_rows_per_band\n",
    "            end_row = start_row + self.num_rows_per_band\n",
    "            band_signature = 0\n",
    "            # Compute band signature\n",
    "            for row in range(start_row, end_row):\n",
    "                band_signature = (band_signature * 31 + int(query_signature[row])) & 0xFFFFFFFF\n",
    "            # Get bucket ID\n",
    "            bucket_id = band_signature\n",
    "            # Query the bucket and update candidates\n",
    "            if bucket_id in self.buckets:\n",
    "                candidates.update(self.buckets[bucket_id])\n",
    "        return candidates\n",
    "\n",
    "    def movie_query(self, tag_query):\n",
    "        \"\"\"\n",
    "        Query movies similar based on tag query.\n",
    "        \"\"\"\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv('temp_gpu.csv')\n",
    "\n",
    "        # Find the first movie with the specified tag\n",
    "        movie_row = df[df['genres'].str.contains(tag_query, case=False, na=False)].iloc[0]\n",
    "        movie_title = movie_row['originalTitle']\n",
    "\n",
    "        # Compute MinHash signature of the selected movie\n",
    "        query_signature = df[df['originalTitle'] == movie_title]['minhash_signature'].values[0]\n",
    "\n",
    "        # Convert signature from string to list of integers\n",
    "        query_signature = eval(query_signature)  # Assuming the signature is stored as a string representation of a list\n",
    "\n",
    "        # Find similar movies using LSH\n",
    "        candidate_movie_ids = self.movie_similar(query_signature)\n",
    "\n",
    "        return candidate_movie_ids\n",
    "    \n",
    "    def show_buckets(self):\n",
    "        print(len(self.buckets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_signature(query_tags, minhash_signatures_func, num_hash_functions=30):\n",
    "    query_shingles = create_shingles(query_tags)\n",
    "    query_dict = {'query_movie': query_shingles}  # Create a dictionary with a single entry for the query movie\n",
    "    query_signatures = minhash_signatures_cuda(query_dict, num_hash_functions)\n",
    "    return query_signatures['query_movie']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minht\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "# Initialize LSH with parameters\n",
    "max_val = 2**16  # Adjust based on your needs\n",
    "lsh = LSH(num_bands=5, num_rows_per_band=2, max_val=max_val)  # Chia chữ ký MinHash thành 5 bands, mỗi band có 2 hàng\n",
    "\n",
    "signatures_dict = df.set_index('originalTitle')['minhash_signature'].to_dict()\n",
    "\n",
    "lsh.insert_parallel(signatures_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truy vấn phim tương tự\n",
    "query_movie = 'Der Hausmeister'\n",
    "query_signature = df[df['originalTitle'] == query_movie]['minhash_signature'].iloc[0]\n",
    "\n",
    "candidate_movies = lsh.movie_similar(query_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Millionaire'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = \"fami\"\n",
    "query_result = lsh.movie_query(tag)\n",
    "query_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
